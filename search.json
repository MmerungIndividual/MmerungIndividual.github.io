[{"title":"hive_2（曦哥版）","url":"/2020/06/28/hive-2/","content":"## 选择题\n1\thive元数据储存的三种模式不包括那个（C）\t\n\tA、\t单用户模式\n\tB、\t多用户模式\n\tC、\t近程服务器模式\n\tD、\t远程服务器模式\n\t\t\n2   Hive支持的分割符，常用的有几种(C)\t\n\tA、\t1\n\tB、\t3\n\tC、\t5\n\tD、\t4\n\t\t\n3\t常用分隔符不包括以下哪个（D）\t\n\tA、\t\\n\n\tB、\t^A\n\tC、\t^B\n\tD、\t^D\n\t\t\n4\tHive提供的哪种客户端访问接口，客户端可以直接在命令行模式下进行操作（A）\t\n\tA、\tHive CLI\n\tB、\thwi\n\tC、\thiveserver\n\t\t\n5\thive中主要包含几种数据模型（C）\t\n\tA、\t1\n\tB、\t2\n\tC、\t3\n\tD、\t4\n\t\t\n6\thive复杂的数据类型不包括以下哪个（A）\t\n\tA、\tstring\n\tB、\tarray\n\tC、\tmap\n\tD、\tstruct\n\n7  以下哪个原子数据类型为1字节（A）\t\n\tA、\tTINYINT\n\tB、\tSAMLLINT\n\tC、\tINT\n\tD、\tBIGINT\n8\t在将数据导出的时候，若数据是用户所需要的文件格式，下列哪个语法是正确的？（D）\n    A.\tHadoop -cp  fs  源文件路径 目标路径\n    B.\tHadoop -cp  fs  目标路径 源文件路径\n    C.\tHadoop fs  -cp  目标路径 源文件路径\n    D.\tHadoop fs  -cp  源文件路径 目标路径\n\n9\t若想要将数据加载到Hive外部表中，有几种方式？（B）\n    A. 1种\n    B. 2种\n    C. 3种\n    D. 4种\n\n10\t下列哪些是能修改的数据库信息？（D）\n    A 元数据 \n    B 数据库名 \n    C 数据库所在目录位置 \n    D 键值对属性值\n\n11\t使用Load DATA 命令，数据会被转移或复制到_____（B）\n    A 本地文件系统路径 \n    B 分布式文件系统路径 \n    C 磁盘 \n    D 内存\n\n12\t通过查询语句向表中插入数据应该使用什么语句？（C）\n    A. SELECT...WHERE 语句 \n    B.ALTER TABLE 语句 \n    C.INSERT语句 \n    D.INSERT.....DIRECTORY语句\n\n13\t在装载数据到表中的过程中，Hive会验证以下什么？（B）\n    A.验证用户装载的数据和表的模式是否匹配   \n    B.验证文件格式是否和表结构定义的一致          \n    C. 两者都要验证         \n    D.两者都不验证\n\n14\tOVERWRITE关键字和INTO关键字的意义是？（B）\n    A.把新增的文件增加到目标文件夹 \n    B.以追加的方式写入数据而不会覆盖掉之前已经存在的内容 \n    C.两者都有 \n    D.以上都不正确\n\n15  对于INPATH字句中使用的文件路径有一个限制，是什么？（A）\n    A. 此路径下不可以包含任何文件夹  \n    B.此路径只能包含一个文件夹                    \n    C. 此路径下最多包含5个文件夹    \n    D.以上均不正确\n\n16  hive的基本数据类型不包括（D）\n    A，int  B,Bigint  C,String  D,Map\n\n17  hive的集合数据类型不包括（B）\n    A，truct  B,Boolean  C,Map  D,Array  \n18  下面（A）是二进制类型：\nA，binary  B,Boolean  C,int  D,Array  \n19  hive默认使用的行分隔符是（A）\nA，\\n  B, ^A  C, ^B  D, \\t\n20 用于分隔ARRARY或者STRUCT中的元素，或用于MAP中键-值对之间的分隔。在CREATE TABLE语句中可以使用八进制编码\\002表示：(C)\nA，\\n  B, ^A  C, ^B  D, \\t\n21 Hive建表方式不包括: (C)\nA，直接建表法  B,查询建表法  C,as建表法  D,like建表法\n22 create table partiton_table(sid int,sname string) partitioned by (gender string) row format delimited fields terminated by ',';这段是创建了一个（C）\nA，内部表  B,外部表  C,分区表  D,关系表\n23 Hive 中所有的数据都存储在 HDFS 中，以下数据模型中不属于hive的是：（D）\nA，内部表  B,外部表  C,分区表  D, 关系表\n24 hive建表时不指定格式时，默认格式为：（A）\nA，TextFile  B, SequenceFile  C,MapFile  D, ORCFile\n25 下列哪一个不是创建内部表：（C）\nA：create table t1(tid int,tname string, gender string); \nB: create table t2(tid int,tname string, gender string) row format delimited fields terminated by ','; \nC：create table t3(tid int,tname string) partitioned by (gender string) row format delimited fields terminated by ',';\nD：create table t4(tid int,tname string, gender string) as select * from t1;\n26 运算符~A数值类型，该如何描述？D\nA.A除以B。如果能整数除则返回商数 \nB.A和B按位取余\nC.A和B按位取与\nD.A按位取反\n27 查询语句中包含有（1-deductons[...]）这个运算，因为deductions字段是FLOAT类型的,因此数字1会提升为什么类型。C\nA.DOUBLE\nB.BIGINT\nC.FLOAT\nD.INT\n28 假设有一个表表示用户偏好，另一个表表示新闻文章，同时有一个算法会推测出用户可能会喜欢读哪些文章。这个时候就需要使用什么来生成所有用户和所有网页的对应关系的集合。B\nA.map-side JOIN\nB.笛卡尔积 JOIN\nC.RIGHT OUTER JOIN\nD.FULL OUTER JOIN\n29 哪个连接会返回左边表的记录，前提是其记录对于右边表满足ON语句中的判定条件。C\nA.笛卡尔积 JOIN\nB.RIGHT OUTER JOIN\nC.LEFT SEMI JOIN\nD.FULL OUTER JOIN\n30 Hive可以在map端执行连接过程，如果所有表中只有一个表是小表，那么可以在最大的表通过什么的时候将小表完全放到内存中。A\nA.mapper\nB.reduce\nC.select\nD.join\n31 DISTRIBUTE BY和GROUP BY在控制reducer如何接受一行行数据进行处理方面是类似的，而SORT BY则控制着什么的数据如何进行排序。A\nA.reduce内\nB.sort\nC.cluster\nD.以上都不是\n32 因为ORDER BY操作可能会导致运行时间过长，如果属性hive.mapred.mode的值是什么的话，那么Hive要求这样的语句必须加有LIMIT语句进行限制。B\nA.nonstrict\nB.strict\n33 SELECT和WHERE语句中不能引用什么表中的字段？B\nA.左边表\nB.右边表\n34 笛卡尔积是一种连接，表示左边表的行数怎么右边表的行数等于笛卡尔结果集的大小。D\nA.除以\nB.相加\nC.相减\nD.乘以\n35 左外连接通过关键字LEFT OUTER进行标识，在这种JOIN连接中，JOIN操作符左边表中符合WHERE子句的所有记录将会被返回。JOIN操作符右边表如果没有符合ON后面连接条件的记录时，那么从右边表制定选择的列的值将会是什么？C\nA.ALL\nB.NON\nC.NULL\nD.都不对\n\n### 多选\n1   Hive常见的数据导入方式有以下哪些（ABCD）\t\n\tA、\t从本地文件系统导入数据到hive表\n\tB、\t从hdfs上导入数据到hive表\n\tC、\t从其它表中查询出相应的数据并导入到hive表中\n\tD、\t在创建表的时候通过从其它的表中查询出相应的记录并插入到所创建的表中\n\t\t\n2   hive数据分为以下包括的是（BC）\t\n\tA、\t单数据\n\tB、\t元数据\n\tC、\t表数据\n\tD、\t多数据\n\n3   Hive数据库可支持如下哪些操作？（ABC）\n    A.创建 B.删除 C.选择 D.复制\n\n4 下列哪个是正确的？（ABCD）\n    A. Hive.exec.dynamic.partition的默认值是false\n    B. Hive.exec.dynamic.partition.mode的默认值是strict                    \n    C. Hive.exec.max.dynamic.partition.penode的默认值是1000\n    D. Hive.exec.max.created.files的默认值是10000   \n## 判断题\n1、元数据是用来存储表的名字、列、分区及其属性以及表的数据所在目录等（√）\n2、hive的数据存储在Hadoop分布式文件系统中（√）\n3、hive元数据储存模式中的多用户模式不需要本地运行一个MySQL服务器（X）\n4、hive原子数据类型中int类型为2字节（X）\n5、hive原子数据类型中double类型为8字节（√）\n6、hive的string数据类型相当于数据库的varchar数据类型（X）\n7、hive和关系数据库存储文件的系统相同（X）\n8、hive很容易扩展自己的储存能力和计算能力（√）\n9、hive元数据中的存储模式其中之一的单用户模式是hive默认的存储模式（√）\n10、表数据是hive中表格具有的数据（√）\n\n1、Hive数据库中的数据库名可以修改。（X）\n2、HIve数据库中的数据库属性信息可以修改。（√）\n3、删除外部表只删除元数据信息。（√）\n4、有external的情况下，不管原表是管理表还是外部表，新生成的表都是外部表。（X）\n5、分区表中分区结构就是HDFS的分区目录。（√）\n6、删除分区表后，元数据和数据将一并被删除，但HDFS对应的分区目录会被保留以便于查询。（X）\n7、设置hive.exec.dynamic.partition.mode为true,可实现使用动态分区功能。（X）\n8、Hive中不允许主分区为动态分区。（√）\n9、Hive中可设置部分列为动态分区，也可以设置所有列为动态分区。（√）\n10、分桶表参数之hive.mapred.mode的默认值是strict模式（√）\n\n1、函数floor、round和ceil（向上取整）输入的是DOUBLE类型的值，而返回的值是BIGINT类型的，也就是将浮点型数转换成整型了。（对）\n2、返回值类型是DOUBLE，样式为degrees（DOUBLE d）将DOUBLE型角度值d转换成弧度值，结果是DOUBLE型的。（错，应该是弧度值转换成角度值）\n3、算数运算符接受任意的数值类型。（对）\n4、如果参与运算的两个数据的数据类型不同，那么两种类型中值的范围较小的那个数据类型将转换为值更大的数据类型。（对）\n5、用户不但可以选择则表中的列，还可以使用函数调用和算术表达式来操作列值。（对）\n6、对于INT类型和BIGINT类型计算，INT类型会转换提升为BIGINT类型；对于INT类型和FLOAT类型运算，INT类型将提升为FLOAT类型的。（对）\n7、CASE...WHEN...THEN语句和if条件语句类似，用于处理多个列的查询结果。（错，处理单个列）\n8、HAVING子句允许用户通过一个简单的语法完成原本需要通过子查询才能对FROUP BY语句产生的分组进行条件过滤的任务。（对）\n9、内连接中，不是只有进行连接的两个表中都存在与链接标准相匹配的数据才会被保留下来。（错，只有两个表都存在才可以）\n10、Hive可以在map端执行连接过程（称为map-side JOIN），这是因为Hive可以和内存中的小表进行逐一匹配，从而省略掉常规连接操作所需要的reduce过程。（对）\n\n1、hive的内置数据类型分为基本数据类型和集合数据类型。（√）\n2、hive中数据模型主要有5种（×）\n3、对于hive的string类型相当于数据库的varchar类型，该类型是一个可变的字符串，不过它不能声明其中最多能存储多少个字符。（√）\n4、hive中默认使用^A(ctrl+A)作为列分割符，如果用户需要指定的话，等同于row format delimited fields terminated by '\\001'（√）\n5、建表的时候一定要根据结构化数据文件的分隔符类型指定分隔符（√）\n6、create table创建一个指定名字的表，如果相同名字的表已经存在，则会覆盖原先的表并清空里面的内容（×）\n7、hive创建外部表时，会将数据移动到数据仓库指向的路径；（×）\n8、桶表是对某一字段进行哈希取值后，放到不同的文件中，从而可以提高查询效率(√)\n9、分区表通常分为静态分区表和动态分区表，前者需要导入数据时静态指定分区，后者可以直接根据导入数据进行分区。（√）\n10、分桶表可以在分区表的基础之上创建，但不可以只创建分桶表。（×）\n## 解答题\n1、Hive数据仓库系统中，支持哪些数据类型？\n基本数据类型和集合数据类型\n2、Hive数据仓库中提供几种分割符，分别是什么？\n5种常用分割符\n分隔符：\\n，^A，^B，^C，\\t\n3、Hive中包含几种数据模型，分别是哪些？\n主要包含表、外部表、分区表和桶四种模型\n4、Hive中提供的几种文件格式，分别是哪些\nTextFile\nSequenceFile\nRCFile\nORC\n5、简述读时模式和写时模式的优缺点\n读时模式:\n优点：写数据很快，load data 效率高\n缺点：读数据比较慢，需要检查数据，解析字段和schema。\n写时模式:\n优点：读非常快\n缺点：写速度很慢\n6、hive提供了哪三种客户端用户访问接口？\nhive CLI\nHWI\nHiveserver\n7、Hive中表的数据默认存储于哪？\nHDFS\n8、hive元数据的三种储存模式\n单用户模式\n多用户模式\n远程服务器模式\n9、简述Hadoop与Hive间关系。\n“hive是hadoop的延申。 hadoop是一个分布式的软件处理框架,hive是一个提供了查询功能的数据仓库。\n1、 hive的原子数据类型可以转换吗？如果可以用什么方法转换呢？\n答：可以。隐式类型转换或者CAST操作显示进行数据类型转换\n2、hive建表的字段顺序和字段类型要跟结构化数据文件的数据类型一致吗？为什么？\n答：要一致。如果类型不一致，hive会尝试转换，不保证转换成功，如果成功就显示，如果失败就显示为null\n5、map keys terminated by ':'请简述这段代码的意思：\n答：集合类型数据元素之间使用英文冒号分隔\n6、请创建一个student_ext的外部表含有id，name,sex的信息，以'，'结尾的行格式分隔字段，且数据在hdfs根目录下的/test/stu\n答：\nCreate external table student_ext(id string,name string,birthday string,sex string) row format delimited fields terminated by ’，'location ’/test/stu’;\n7、请问通过create table test1 like test创建的test1和通过\nCreate table test2 AS SELECT id,name,gfs,adress from test创建的test2的表是否一样，如果不是，请问差别在哪里？\n答：不一样。test1只创建表结构，test2不仅创建相应的表结构，并且会插入数据。\n8、hive种内部表和和外部表的创建和删除有哪些区别：\n答：hive创建内部表时，会将数据移动到数据仓库指向的路径，删除表的时候元数据和数据会被一起删除。\nhive创建外部表时，烬记录数据所在的路径，不对数据的位置做任何改变，，删除表的时候只删除元数据，不删除数据。\n1：Hive中内部表如何标识，内部表有哪些操作？\n   内部表创建和传统数据库一样，没有标识关键字；内部表有create、drop、show等操作。\n2：怎么操作可以显示当前所在的数据库？\n   Set hive.cli.print.current.db=true\n3:  create...as....select语法为什么不能应用于外部表？\n  因为外部表本身没有进行数据装载，只有表结构和元数据。\n4：为什么要进行分桶？\n取样更高效，以及获得更好的查询处理效率。\n5：请写出桶抽样的的语法，并说明参数X和Y分别代表什么含义？\n语法：tablesample（bucket x out of y on）y决定抽样比例，即：抽取桶样本个数；x决定起始样本，即：从哪个桶开始选取。\n6：请写出“创建表student，按照line分区，按照uid分为32分桶”语句\nCreate table student（\nuid INT,\nLine STRING)\nPARTITIONED BY(line STRING)\nCLUSTERED BY(uid) BY(uid ASC) INTO 32 BUCKETS;\n7:简述Hive中内部表的内容\n内部表类比于数据库中表， 每个内部表在Hive中都有一个对应的存储数据的目录，可以删除表，删除元数据和数据\n1·\t用代码说明：①如何删除数据库，②以及当数据库中存在表时能否删除 以及用文字说明在什么情况下不能删除\n①drop database if exists myhive ②drop database if exits myhive cascade 默认情况下为restrict，不能删除。\n2·\t写出代码以实现创建数据库的操作\nCREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name [COMMENT database_comment] [LOCATION hdfs_path\n[WITH DBPROPERTIES (property_name=property_value, ...)];\n3·\t简述静态分区和动态分区的关系\n有静态分区，可以没有动态分区，有动态分区，默认至少有一个静态分区\n1、聚合函数是一类比较特殊的函数。其可以对多行进行一些计算，然后得到一个结果值。更确切的说，这是用户自定义聚合函数，这类函数中最有名的两个例子是哪两个？分别用于什么。\n答：两个例子是count和avg。函数count用于计算有多少行数据（或者某列有多少值），而函数avg可以返回指定列的平均值。\n\n2、当进行算术运算时，需要注意什么问题？请详细说明。\n答：需要注意数据溢出或数据下溢问题。Hive遵循的底层Java中数据类型的规则，因此当溢出或下溢发生时计算结果不会自动转换为更广泛的数据类型。乘法和除法最有可能会引发这个问题。\n\n3、与聚合函数“相反的”一类函数是什么函数？它可以做什么？\n答：相反的一类函数是表生成函数，它可以将单列扩展成多列或者多行。\n\n4、SELECT语句用于什么？WHERE语句用于什么？两者结合使用又可以做什么？\n答：select语句用于选取字段，where语句用于过滤条件，两者结合使用可以查找到符合过滤条件的记录。\n\n5、GROUP BY语句通常会和聚合函数一起使用，怎么分组呢？\n答：按照一个或者多个列对结果进行分组，然后对每个组执行聚合操作。\n\n6、Hive可以在map端执行连接过程，Hive对于哪两个连接不支持这个优化。\n答：右外连接（RIGHT OUTER JOIN）和全外连接（FULL OUTER JOIN）\n\n7、UNION ALL可以将两个或多个表进行合并，每一个UNION子查询需要具有什么条件？\n答：每一个UNION子查询都必需具有相同的列，而且对应的每个字段的数据类型都必须是一致的。\n\n8、对于非常大的数据集，如何满足用户需要的是一个具有代表性的查询结果而不是全部结果？\n答：Hive可以通过对表进行分桶抽样来满足这个需求。\n\n9、如果所有表中的数据是分桶的，那么在特定的情况下对于大表同样可以使用map-side JOIN，请简单描述下应满足的条件。\n答：简单地说，表中的数据必须是按照ON语句中的键进行分桶的，而且其中一个表的分桶的个数必须是另一个表分桶个数的若干倍。当满足这些条件时，Hive可以在map阶段按照分桶数据进行连接。\n\n10、MapReduce job中传输的所有数据都是按照键值对的方式进行组织的，什么时候必须在内部使用这个功能？\n答：Hive在将用户的查询语句转换成MapReduce job时，其必须在内部使用这个功能。\n\n\n","tags":["答案"]},{"title":"软件工程","url":"/2020/06/24/软件工程/","content":"## 软件工程知识部分\n### 概述\n软件工程是指导计算机软件**开发**和**维护**的工程科学。\n软件工程是一门**综合性交叉**学科，计算机学着重于理论和科学 ， \n软件工程着重于**设计实现软件系统** 。\n### 软件的生命周期\n软件生命期分为7大阶段:  \n①　问题定义：要解决的问题是什么\n②　可行性研究：确定问题是否值得解，技术可行性、经济可行性、操作可行性\n③　需求分析：系统必须做什么 \n④　总体设计：系统如何实现，包括系统设计和结构设计 \n⑤　详细设计：具体实现设计的系统\n⑥　实现：编码和测试 \n⑦　运行维护：保证软件正常运行。\n软件生存周期的三大阶段：计划阶段、开发阶段、维护阶段。\n软件生命周期花费最多的阶段是**软件维护**。\n软件可行性研究包括：技术可行性、经济可行性、法律可行性。\n软件详细设计的主要任务是确定每个模块的算法和使用的数据结构。\n需求分析阶段产生的最重要的文档之一是需求规格说明书。\n### 数据流图和数据字典\n数据流图（DFD）中的每个数据处理至少需要一个输出数据流。\n数据流图中的箭头表示 数据流 ，椭圆或圆形表示 事务处理（数据处理） ，矩形表示 数据圆点点/终点。\n结构化程序设计的一种基本方法是**逐步求精法**。\n数据字典是软件需求分析阶段的最重要工具之一，其最基本的功能是数据定义。\n数据字典中有4类条目：数据流、数据项、 数据存储  、加工  \n数据字典是用来定 数据流图中的各个成分的具体含义的\n### 白箱测试技术\n白盒测试技术包括：.逻辑覆盖、基本路径测试、循环覆盖测试\n白盒测试技术测试用例的设计中，语句覆盖是最弱的覆盖标准。\n### 其他\n程序的三种基本结构是顺序、选择、循环\n耦合：软件结构中模块之间互相依赖的程度。\n（1）数据耦合\n（2）控制耦合\n（3）公共环境耦合\n（4）内容耦合\n## UML知识部分\n### UML体系\nUML体系包括三个部分：UML 基本构造块，UML规则 和 UML 公共机制。\n统一建模语言(UML)概念：统一建模语言(UML)是一种绘制软件蓝图的标准语言。可以用 UML 对软件密集型系统的制品进行可视化详述和文档化。UML 是一种定义良好、易于表达、功能强大且普遍适用的可视化建模语言。它融入了软件工程领域的新思想、新方法和新技术。它的作用域不限于支持面向对象的分析与设计，还支持从需求分析开始的软件开发的全过程。UML 的作用就是用很多图从静态和动态方面来全面描述我们将要开发的系统。\n面向对象的开发方法中,面向对象技术领域内占主导地位的标准建模语言是UML语言。\n面向对象方法的要素是对象、类、继承和消息。\n面向对象程序的基本特征是： **抽象** 、 **封装** 、 **继承** 和 **多态** \n在UML提供的图中，用例图用于描述系统与外部系统及用户之间的交互。\n用例图由参与者（Actor）、用例（Use Case）以及它们之间的关系构成的用于描述系统功能的图成为用例。执行者（Actor）与用例之间的关系是**关联关系**。\n\n用例图功能:\n（1）用例图是从软件需求分析到最终实现的第一步，它显示了系统的用户和用户希望提供的功能，有利于用户和软件开发人员之间的沟通。\n（2）用例图可视化的表达了系统的需求，具有直观、规范等优点，克服了纯文字性说明的不足.\n（3）用例方法是完全从外部来定义系统的，它把需求和设计完全分离开来，使用户不用关心系统内部是如何完成各种功能的 。\n\n在 UML 用例图中，椭圆表示 用例 ，方框表示 系统边界 ，小人状图案表示 执行者\t。\nUML 提供了一系列的图支持面向对象的分析与设计，其中类图给出系统的静态设计视图；用例图对系统的行为进行组织和建模是非常重要的；顺序图和协作图都是描述系统动态视图的交互图，其中顺序图描述了以时间顺序组织的对象之间的交互活动，协作图强调收发消息的对象的组织结构。\n顺序图包含4个元素，分别是对象、生命线、消息和激活\n面向对象中类与类之间的关系有四种:\n①　泛化关系:泛化是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为.\n②　实现关系：用于规定规格说明与其实现之间的关系，换句话说，就是指定两个实体之间的一个合同，一个实体定义一个合同，而另一个实体保证履行该合同。\n③　关联关系：对象之间的关系准则。又分聚合关系和组合关系.\n④　依赖关系：当两个元素处于依赖关系中时，其中一个元素的改变可能会影响或提供消息给另一个元素，即另一个元素以某种形式依赖于另一个元素。\n\nUML状态图:描述一个对象的生命周期的.\nUML类图:用户根据用例图抽象成类，描述类的内部结构和类与类之间的关系，是一种静态结构图。 在UML类图中，常见的有以下几种关系: 泛化（Generalization）, 实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)。\n各种关系的强弱顺序： 泛化 = 实现 > 组合 > 聚合 > 关联 > 依赖\nUML活动图：第二代面向对象技术的标志。请熟悉活动图中各个模型元素。\nUML协作图特点:交互图的一种，描述了收发消息的对象的组织关系，强调对象之间的合作关系。时序图按照时间顺序布图，而写作图按照空间结构布图\nUML顺序图特点:交互图的一种，描述了对象之间消息发送的先后顺序，强调时间顺序。[详情链接](https://zhuanlan.zhihu.com/p/44518805)\n\nRUP 统一过程中的四个阶段：初始阶段、细化阶段、构造阶段、提交阶段。\nUML 中的交互图有两种，分别是顺序图和协作图，请分析一下两者之间的主要差别和各自的优缺点。掌握利用两种图进行的设计的方法。\n协作图可视化地表示了对象之间随时间发生的交互，它除了展示对象之间的关联，还显示出对象之间的消息传递。与顺序图一样，协作图也展示对象之间的交互关系。顺序图强调的是交互的时间顺序，而协作图强调的是交互的语境和参与交互的对象的整体组织。顺序图按照时间顺序布图，而协作图按照空间组织布图。\n顺序图可以清晰地表示消息之间的顺序和时间关系，但需要较多的水平方向的空间。\n协作图在增加对象时比较容易，而且分支也比较少，但如果消息比较多时难以表示消息之间的顺序。\n\n\n\n\n\n","tags":["答案"]},{"title":"数据结构第7章 图","url":"/2020/06/19/图/","content":"## 图的邻接矩阵表示法\n```\n#define MAXVUM 1000;\ntypedef char varTex;\ntypedef int ArcTex;\ntypdef struct{\n    varTex vexs[MAXVUM];\n    ArcTex arcs[MAXVUM][MAXVUM];\n    int vum,arcnum;\n}Graph;\n```\n使用邻接矩阵创建无向图\n```\n#define MaxInt 31242;\nStatus createUdm(Graph &G){\n    int i;\n    int j;\n    int k;\n    cin<<arcnum<<texnum\n    for(i=0;i<texnum;i++){\n        cin<<G.vex[i];\n    }\n    for(i=0;i<texnum;i++){\n    for(j=0;j<texnum;j++){\n        arcs[i][j]=MaxInt;\n    }\n    }\n    for(k=0;k<arcnum;k++){\n        cin<<v1<<v2<<w;\n        i=locate(v1);\n        j=locate(v2);\n        G.arcs[i][j]=w;\n        G.arcs[j][i]=G.arcs[i][j];\n    }\n}\n```\n## 图的邻接表存储方式\n```\ntypedef struct ArcNode{\nint v;\nstruct ArcNode* next;\nint info;\n}ArcNode;\ntypedef struct VNode{\n    int data;\n    arcnode* first;\n}VNode,adjlist[MVNum];\ntypedef struct{\nadjlist vertices;\nint vexnum,arcnum;\n}algraph;\n```","tags":["数据结构与算法"]},{"title":"数据结构第6章 树和二叉树","url":"/2020/06/18/树和二叉树/","content":"## 二叉树的性质\n性质1.二叉树的第i层至多有2的i-1次方个结点\n性质2.深度为k的二叉树至多有2的k次方减1个结点\n性质3.n0=n2+1\n性质4.具有n个结点的完全二叉树的深度为$[log_2n]+1$\n## 二叉树的链式存储\n```\ntypedef struct BTNode{\n    int data;\n    struct BTNode* leftchild,rightchild;\n}BTNode,*Bitree;\n```\n## 中序遍历的递归算法\n```\nvoid InOrderTraverse(Bitree T){\n    if(T){\n        InOrderTraverse(T->leftchild);\n        cout<<T->data;\n        InOrderTraverse(T->rightchild);\n    }\n}\n```\n## 中序遍历的非递归算法\n```\nvoid NoneOrderTraverse(Bitree T){\n    InitStack(S);\n    p=T;\n    q=new BiTNode;\n    while(p!=Null||isEmpty(S)){\n        if(p){\n            push(S,p);\n            p=p->leftchild;\n        }\n        else{\n            pop(S,q);\n            cout<<q->data;\n            p=q-rightchild;\n        }\n    }\n}\n```\n## 二叉树的二叉线索表示\n```\ntypedef struct BitrdNode{\nint data;\nint lTag;\nint rTag;\nBitrdTree *lchild,rchild;\n}BitrdNode,*BitrdTree;\n```\n## 以结点p为根的子树中序线索化\n```\nvoid InitTreading(BitrdTree T){\n    //pre是全局变量\n    if(p){\n        InitTreading(p->lchild);\n        if(!p->lchild){\n            p->lTag=1;\n            p->lchild=pre;\n        }\n        else p->lTag=0;\n        if(!pre->rchild){\n            pre->rTag=1;\n            pre->rchild=p;\n        }\n        else pre->rTag=0;\n        pre=p;\n        InitThreading(p->rchild);\n    }\n}\n```\n## 遍历中序搜索二叉树\n```\nvoid AllSearch(BitrdTree T){\n    p=T.lchild;\n    while(p){\n        while(p->lTag==0)p=p->lchild;\n        cout<<p->data;\n    while(p->rTag==1&&p!=T){\n        p=p->rchild;cout<<p->data;\n    }\n    p=p->rchild;\n    }   \n}\n```","tags":["数据结构与算法"]},{"title":"计算机网络第2章 物理层","url":"/2020/06/16/物理层/","content":"## 2.1.1物理层的基本概念\n物理层的主要任务描述为确定与传输媒体的接口有关的一些特性，即(1)机械特性(2)电器特性(3)功能特性(4)过程特性\n## 2.2.2有关信道的几个基本概念\n从通信双方的信息交互方式来看，可以有以下三种方式(1)单向通信(2)双向交替通信(3)双向同时通信。调制可以分两类，一类是仅仅对基带信号的波形进行变换。变换后信号仍然是基带信号。这类调制叫基带调制。另一类调制则需要使用载波进行调制，把基带信号的频率范围跳到较高的频段，并转换为模拟信号。经过载波调制后的信号称为带通信号，而使用载波的调制称为带通调制。\n常用的编码方式，不归零制，归零制，曼切斯特编码，差分曼切斯特编码。\n基本的带通调制方法，调频，调幅，调相。\n## 2.2.3信噪比和香农公式\n信噪比计算公式：信噪比=$10\\log_{10}(S/N)(dB)$  \n香农公式：$C=W\\log_2(1+S/N)(bit/s)$信道的极限传输速率为C\n##信道复用技术\n主要有频分复用，时分复用，统计时分复用，码分复用，波分复用","tags":["计算机网络"]},{"title":"数据结构第4章 串和模式匹配","url":"/2020/06/16/数据结构第5章 广义表/","content":"## 1.串的存储结构\n顺序存储结构\n```\n#define MAXSIZE 100\ntypedef struct{\n    char ch[MAXSIZE+1];\n    int length;\n}SString;\n```\n堆式存储结构\n```\ntypedef struct{\n    char ch*;\n    int length;\n}HString;\n```\n## 2.模式匹配算法\n### 2.1BF算法\n```\nint Index_BF(SString S,SString T,int pos){\n    int j=1,i=pos;\n    while(i<=S.length&&j<=T.length){\n        if(S.ch[i]==S.ch[j]){\n            ++i;++j;\n        }\n        else{\n            j=1;\n            i=i-j+2;\n        }\n    }\n    if(j>T.length) return i-T.length;\n    else return 0;\n}\n```\n### 2.2KMP算法\n```\nint Index_KMP(SString S,SString T,int pos{\nint j=1,i=pos;\nwhile(j<=T.length&&i<=S.length){\n    if(S.ch[i]==T.ch[j]){\n        ++i;\n        ++j;\n    }\n    else{\n        j=next[j];\n    }\n}\n  if(j>T.length) return i-T.length;\n    else return 0;\n}\n```\n计算next函数值\n```\nvoid get_next(SString T,int[] next){\n    int j=0;\n    int i=1;\n    next[1]=0\n    if(j==0||T.ch[i]==T.ch[j]){++i;++j;next[i]=j;};\n    else{\n        j=next[j];\n    }\n}\n```","tags":["数据结构与算法"]},{"title":"hive","url":"/2020/06/15/post/","content":"1、运算符~A数值类型，该如何描述？D\nA.A除以B。如果能整数除则返回商数 \nB.A和B按位取余\nC.A和B按位取与\nD.A按位取反\n2、查询语句中包含有（1-deductons[...]）这个运算，因为deductions字段是FLOAT类型的,因此数字1会提升为什么类型。C\nA.DOUBLE\nB.BIGINT\nC.FLOAT\nD.INT\n3、假设有一个表表示用户偏好，另一个表表示新闻文章，同时有一个算法会推测出用户可能会喜欢读哪些文章。这个时候就需要使用什么来生成所有用户和所有网页的对应关系的集合。B\nA.map-side JOIN\nB.笛卡尔积 JOIN\nC.RIGHT OUTER JOIN\nD.FULL OUTER JOIN\n4、哪个连接会返回左边表的记录，前提是其记录对于右边表满足ON语句中的判定条件。C\nA.笛卡尔积 JOIN\nB.RIGHT OUTER JOIN\nC.LEFT SEMI JOIN\nD.FULL OUTER JOIN\n5、Hive可以在map端执行连接过程，如果所有表中只有一个表是小表，那么可以在最大的表通过什么的时候将小表完全放到内存中。A\nA.mapper\nB.reduce\nC.select\nD.join\n6、DISTRIBUTE BY和GROUP BY在控制reducer如何接受一行行数据进行处理方面是类似的，而SORT BY则控制着什么的数据如何进行排序。A\nA.reduce内\nB.sort\nC.cluster\nD.以上都不是\n7、因为ORDER BY操作可能会导致运行时间过长，如果属性hive.mapred.mode的值是什么的话，那么Hive要求这样的语句必须加有LIMIT语句进行限制。B\nA.nonstrict\nB.strict\n8、SELECT和WHERE语句中不能引用什么表中的字段？B\nA.左边表\nB.右边表\n9、笛卡尔积是一种连接，表示左边表的行数怎么右边表的行数等于笛卡尔结果集的大小。D\nA.除以\nB.相加\nC.相减\nD.乘以\n10、左外连接通过关键字LEFT OUTER进行标识，在这种JOIN连接中，JOIN操作符左边表中符合WHERE子句的所有记录将会被返回。JOIN操作符右边表如果没有符合ON后面连接条件的记录时，那么从右边表制定选择的列的值将会是什么？C\nA.ALL\nB.NON\nC.NULL\nD.都不对\n二、判断题\n1、函数floor、round和ceil（向上取整）输入的是DOUBLE类型的值，而返回的值是BIGINT类型的，也就是将浮点型数转换成整型了。√\n2、返回值类型是DOUBLE，样式为degrees（DOUBLE d）将DOUBLE型角度值d转换成弧度值，结果是DOUBLE型的。×\n3、算数运算符接受任意的数值类型。√\n4、如果参与运算的两个数据的数据类型不同，那么两种类型中值的范围较小的那个数据类型将转换为值更大的数据类型。√\n5、用户不但可以选择则表中的列，还可以使用函数调用和算术表达式来操作列值。√\n6、对于INT类型和BIGINT类型计算，INT类型会转换提升为BIGINT类型；对于INT类型和FLOAT类型运算，INT类型将提升为FLOAT类型的。√\n7、CASE...WHEN...THEN语句和if条件语句类似，用于处理多个列的查询结果。×\n8、HAVING子句允许用户通过一个简单的语法完成原本需要通过子查询才能对FROUP BY语句产生的分组进行条件过滤的任务。√\n9、内连接中，不是只有进行连接的两个表中都存在与链接标准相匹配的数据才会被保留下来。×\n10、Hive可以在map端执行连接过程（称为map-side JOIN），这是因为Hive可以和内存中的小表进行逐一匹配，从而省略掉常规连接操作所需要的reduce过程。√[链接](https://blog.csdn.net/jinesse/article/details/80575991)\n三、解答题\n1、聚合函数是一类比较特殊的函数。其可以对多行进行一些计算，然后得到一个结果值。更确切的说，这是用户自定义聚合函数，这类函数中最有名的两个例子是哪两个？分别用于什么。\n聚合函数是一类比较特殊的函数，可以对多行进行一些计算，然后得到一个结果值，这类函数中最有名的两个例子就是count和avg，分别计算行数和平均值。[链接](https://www.jianshu.com/p/96b7b2b850bd)\n\n2、当进行算术运算时，需要注意什么问题？请详细说明。\n当进行算术运算时，用户需要注意数据溢出或数据下溢问题，Hive 遵循的是底层 Java 中数据类型的规则，因为当溢出或下溢发生时计算结果不会自动转换为更广泛的数据类型，乘法和除法最有可能会引发这个问题；[链接](https://www.cnblogs.com/jiuyi/p/4232452.html)\n\n3、与聚合函数“相反的”一类函数是什么函数？它可以做什么？\n与聚合函数“相反的”一类函数就是所谓的表生成函数，其可以将单列扩展成多列或者 多行。[链接](https://www.pianshen.com/article/1510470597/)\n\n4、SELECT语句用于什么？WHERE语句用于什么？两者结合使用又可以做什么？\n SELECT语句用于选取字段,WHERE语句用于过滤条件,两者结合使用可以查找到符合过滤条件的记录。\n\n5、GROUP BY语句通常会和聚合函数一起使用，怎么分组呢？\nGROUP BY语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个执行聚合操作。[link](https://www.jianshu.com/p/ef4c9fb3bd5c)\n\n6、Hive可以在map端执行连接过程，Hive对于哪两个连接不支持这个优化。\nHive对于右外连接和全外连接不支持这个优化。\n\n7、UNION ALL可以将两个或多个表进行合并，每一个UNION子查询需要具有什么条件？\n只要结果集中的列数一致就可以.\n\n8、对于非常大的数据集，如何满足用户需要的是一个具有代表性的查询结果而不是全部结果？对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive可以通过对表进行抽样来满足这个需求。[link](https://blog.csdn.net/tyf2007635/article/details/98281835)\n\n9、如果所有表中的数据是分桶的，那么在特定的情况下对于大表同样可以使用map-side JOIN，请简单描述下应满足的条件。\n如果所有表中的数据是分桶的，那么对于大表，在特定的情况下同样可以使用这个优化，简单地说，表中的数据必须是按照ON语句中的键进行分桶的，而且其中一张表的分桶的个数必须是另一张表分桶个数的若干倍。[link](https://blog.csdn.net/xxydzyr/article/details/101012232)\n\n10、MapReduce job中传输的所有数据都是按照键值对的方式进行组织的，什么时候必须在内部使用这个功能？\nMapReduce job中传输的所有数据都是按照键值对的方式进行组织的，因此Hive在将用户的查询语句转换成MapReducejob时，其必须在内部使用这个功能。[link](https://blog.csdn.net/anzhouzan0567/article/details/101593144)\n","tags":["答案"]},{"title":"Java Stream Api","url":"/2020/03/18/Java-Stream-Api/","content":"\n不是数据结构;\n它没有内部存储，它只是用操作管道从source（数据结构、数组、generator function、IO channel）抓取数据;\n它也绝不修改自己所封装的底层数据结构的数据。例如Stream的filter操作会产生一个不包含被过滤元素的新Stream，而不是从source删除那些元素;\n所有Stream的操作必须以lambda表达式为参数;\n不支持索引访问;\n你可以请求第一个元素，但无法请求第二个，第三个，或最后一个;\n很容易生成数组或者List;\n惰性化;\n很多Stream操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始;\nIntermediate操作永远是惰性化的;\n并行能力;\n当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的;\n可以是无限的。集合有固定大小，Stream 则不必。limit(n)和findFirst()这类的short-circuiting操作可以对无限的Stream进行运算并很快完成。\n","tags":["大数据技术"]},{"title":"古代中国性格迥异的帝王","url":"/2020/03/01/古代中国性格迥异的帝王/","content":"Sima Yan (236-290), the Emperor Wu of Jin, was the founder of Jin Dynasty. It was said that he had as much as 10,000 concubines. He once issued an imperial edict to “prohibit marriage” for years and carried out large-scale beauty pageants to select women for him, which increased his harem concubines by more than 5,000 beautiful women. He had so many concubines that it was difficult for him to decide which concubine to spend the night with. So he thought of a weird way, he sat in a cart drawn by sheep and let them walk randomly in the palace, he would spent night with the lucky girl inside the room where the sheep stopped.\n\nQianlong Emperor (1711 – 1799) of Qing Dynasty is familiar to Chinese people, but he also has another status – poet. He is the poet with the most poems in the world. According to records, he composed 41863 poems in his life. While the poem collection “Quan Tang Shi” (Complete Tang Poems), the largest collection of Tang poetry, had only 48,000 from more than 2200 authors. Qianlong`s life span was 89 years which was equivalent to around 32,000 days. Removing his childhood, he had less than 30,000 days to write poetry. It means that he created more than one poem per day.\n\nZhu Youtang (1470-1505), Emperor Xiaozong of Ming Dynasty, was the only emperor who had only one wife. He only married a empress surnamed Zhang and had no concubines. They lived together like living life of ordinary people. It was not easy to do so as an emperor. It is said that he also invented the world’s first toothbrush.","tags":["外文阅读搬运"]},{"title":"Python数据分析与挖掘(一) 拉格朗日插值法","url":"/2020/01/03/Python数据分析与挖掘-一/","content":"拉格朗日插值法：根据数学知识可知，对于平面上已知的n个点，可以找到一个n-1次多项式，使此多项式曲线过n个点，语言：Python\n```bash\n#拉格朗日插值代码\nimport pandas as pd #导入数据分析库Pandas\nfrom scipy.interpolate import lagrange #导入拉格朗日插值函数\n\ninputfile = '../chapter4/demo/data/catering_sale.xls' #销量数据路径\noutputfile = '../chapter4/demo/data/sales.xls' #输出数据路径\ndata = pd.read_excel(inputfile) #读入数据\ndata[u'销量'][(data[u'销量'] < 400) | (data[u'销量'] > 5000)] = None #过滤异常值，将其变为空值\nprint(data.columns)\n#自定义列向量插值函数\n#s为列向量，n为被插值的位置，k为取前后的数据个数，默认为5\ndef ployinterp_column(s, n, k=5):\n  y = s[list(range(n-k, n)) + list(range(n+1, n+1+k))]#取数\n  y = y[y.notnull()] #剔除空值,返回一个没有空值的列向量\n  return lagrange(y.index, list(y))(n) #插值并返回插值结果\n\n#逐个元素判断是否需要插值\nfor i in data.columns:\n  for j in range(len(data)):\n    if (data[i].isnull())[j]: #如果为空即插值。\n      data[i][j] = ployinterp_column(data[i], j)\n\ndata.to_excel(outputfile) #输出结果，写入文件\n```\nlangrange(x,y)(n)这个函数表示插入缺失值所在的下标n，并用插值多项式得到近似值，详情请使用文档查看，jupyter查看方法：移动光标到相应位置shift+tab。","tags":["大数据技术"]},{"title":"Scala辅导班（二）集和映射","url":"/2020/01/02/Scala辅导班（二）集和映射/","content":"## 集和映射\n集（set）：可变集和不可变集\n映射（Map）：可变映射和不可变映射\n可变与不可变分别继承于scala.collection.mutable._和scala.collection.immutable._\n测试的完整代码如下\n```bash\nobject mapAndSet {\n  def main(args:Array[String]){\n    var jetSet = Set(\"test\",\"exam\")//不可变集\n    val jetSet2 = mutable.Set(\"tiny2\",\"nico\")\n    jetSet+=\"tiny\"\n    jetSet2+=\"negopa\"\n    println(jetSet)\n    println(jetSet2)\n    val treasureMap = mutable.Map[Int,String]()\n    treasureMap+=(1 -> \"My\")\n    treasureMap+=(2 -> \"Name\")\n    treasureMap+=(3 -> \"is\")\n    println(treasureMap(2))\n    val rumerNum = Map(1 -> \"I\",2 -> \"II\",3 -> \"III\",4 -> \"IV\")//不可变映射\n    rumerNum.foreach(s => println(s._2))\n  }\n}\n```","tags":["语言学习基础"]},{"title":"Scala辅导班(一) 使用列表","url":"/2019/12/31/Scala辅导班（一）使用列表/","content":"新年快乐，2020，向前冲！\n语言：scala 2.12\n## 数组定义\n```bash\nval numNames = Array(\"num1\",\"num2\",\"num3\")\n```\n数组定义的一般形式\n```bash\nval numNames2 = Array.apply(\"num1\",\"num2\",\"num3\")\n```\n数组定义的等价形式，使用apply方法，scala语言的本质\n## 列表定义\n```bash\nval OneTwo = List(1,2)\nval ThreeFour = List(3,4)\n```\n列表定义\n```bash\nval OneTwoThreeFour = OneTwo ::: ThreeFour\n```\n列表衔接\n```bash\nval TwoThreeFour = 2::ThreeFour\n```\n向表头添加元素，为什么是向头部添加，因为向后添加会消耗线性时间，与其这样不如向表头添加，再通过反转，就能完成同样的功能\n## 列表常用方法\n```bash\nval thrill = \"nil\"::\"sekiro\"::\"thunder\"::Nil\nprint(thrill.count(s => s.length>=4))\nprint(thrill.filter(s => s.length>=4))\nprint(thrill.forall(s => s.endsWith(\"l\")))\nthrill.foreach(s => println(s))\nprint(thrill.mkString(\",\"))//返回以\",\"分割组成的一个列表\n```\n自己动手实践，不多讲","tags":["语言学习基础"]},{"title":"Spark学习（二）概念梳理","url":"/2019/12/29/Spark学习（二）概念梳理/","content":"\n伟大领袖，天降伟人的刘老师给我们的spark概念图\n{% img /img/Spark.png 800 450 %}\n## 分区\nSpark的分区是逻辑上的分区。执行过程中有多少个Task是由RDD分区决定的。同时运行几个Task是由分配给Executor的Core的数量决定的。\n## 什么时候分区\n·分区数量从少到多·处理能力不够·数据倾斜·需要合并场景\n## cache缓存\n持久化方法，将RDD放入内存中，减少重复计算,一共有12种\n    例：\n    ```bash\n    val MEMORY_AND_DISK = new StorageLevel(true, true, false, true)\n    ```\n//第一个参数，放到磁盘\n    //第二个参数，放到内存\n    //第三个参数，磁盘中的数据，不是以java对象的方式保存\n    //第四个参数，内存中的数据，以java对象的方式保存\n## checkpoint机制\n将RDD存储在本地磁盘或者HDFS中，通过直接读取检查点目录的数据来恢复相应的RDD\n## 宽依赖窄依赖\n    宽依赖：一个父RDD和一个或多个子RDD\n    窄依赖：一个子RDD和一个或多个父RDD\n## 广播\n将数据块缓存到所有节点\n## 启动流程(9step)\n    1、跟Master建连接并申请资源，每个Executor需要 3g 内存，一共4 cores\n    2、Master进行资源调度\n    3、Master跟Worker进行rpc通信，让Worker创建Executor\n    4、Worker启动Executor\n    5、Executor跟Driver进行通信\n    6、RDD触发Action后，会根据最后这个RDD从后往前推断依赖关系，遇到shufle就切分Stage，会递归切分，递归的出口是某个RDD没有父BDD了\n    7、DAGScheduler切分完Stage后，先提交前面的Stage,执行完后在提交后面的Stage，Stage会生产Task，一个Stage 会生产很多业务逻辑相同的Task，然后将以TaskSet的形式传递给TaskScheduler\n    8、 TaskScheduler将Task序列化，根据资源情况，发送Task给Executor\n    9、Executor接收到Task后，先将Task反序列化，然后将Task用一个实现了Runnable接口的实现类包装起来，然后将该包装类丢入到线程池，然后包装类的run方法就会被执行，进而调用Task的计算逻辑\n## DStream\nDstream为每一批次的数据生成一个RDD实例，就是一个RDD序列\n## 几何平均数\n{% img /img/jihe.png 150 100 %}\n## UDF用户自定义函数\n一对一的用户定义函数，例如\n```bash\nspark.sql(\"SELECT name,age,from_unixtime(create_time,'yyyy-MM-dd HH:mm:ss') FROM t_usr\").show\n```\n实现用户自定义函数\n```bash\nspark.udf.register(\"func_name\",方法体)\n```\n多进一出UDAF（多对一）\n","tags":["大数据技术"]},{"title":"Spark学习（一）Spark集群模式讲解","url":"/2019/12/28/Spark学习（一）Spark集群模式讲解/","content":"  小坚又被Spark教训了，下面重点讲解Spark的集群\n  下面详细列举了Spark目前支持的部署模式。\n· Local模式：在本地部署单个Spark服务\n· Standalone模式：Spark自带的任务调度模式（国内常用)\n· Yarn模式：Spark使用Hadoop的YARN组件来进行\n· Mesos模式：Spark使用Mesos平台进行资源与任务的调度\n· Kubernetes模式：自Spark2.3.x版本之后才开始支持Kubernetes","tags":["大数据技术"]},{"title":"数据结构与算法（五）科赫曲线","url":"/2019/12/21/数据结构与算法（五）科赫曲线/","content":"语言：python\n递归就是常说的套娃，\n在递归函数中直接或间接调用函数，就是递归\n科赫曲线是在无限的长度中圈定有限的面积，\n实现为三步：1.找到三等分点S,T 2.做等边三角形 3.再对线段进行调用\n```bash\n#科赫曲线\nimport turtle as t\ndef koth(size,n):\n    if n==0:\n        t.fd(size)\n    else:\n        for seta in [0,60,-120,60]:\n            t.left(seta)\n            koth(size/3,n-1)\nif __name__ == '__main__':\n    koth(200,3)\n```","tags":["数据结构与算法"]},{"title":"数据结构与算法（四）穷举搜索","url":"/2019/12/21/数据结构与算法（四）穷举搜索/","content":"运行环境：python 3.7 Dev-C++\n判断是否A中的任意元素都能能够组成整数m?\npython版:\n```bash\nA = [1,5,7,10,21]\nn = len(A)\ndef solve(i,m):\n    if m==0:\n        return True\n    elif i>=n:\n        return False\n    res = solve(i+1,m) or solve(i+1,m-A[i])\n    return res\nif __name__ == '__main__':\n        if(solve(0,8)):\n            print(\"yes\")\n        else:\n            print(\"no\")\n```\nc语言版:\n```bash\n#include<stdio.h>\nint n,A[50];\nint solve(int i,int m){\n\tif (m ==0)return 1;\n\tif (i>=n)return 0;\n\tint res = solve(i+1,m)||solve(i+1,m-A[i]);\n\treturn res; \n} \nint main(){\n\tint q,M,i;\n\tscanf(\"%d\",&n);\n\tfor(i=0;i<n;i++) scanf(\"%d\",&A[i]);\n\tscanf(\"%d\",&q);\n\tfor(i=0;i<q;i++){\n\t  scanf(\"%d\",&M);\n\t  if(solve(0,M)) printf(\"yes\\n\");\n\t  else printf(\"no\\n\"); \n}\nreturn 0;\n}\n```\n","tags":["数据结构与算法"]},{"title":"数据结构与算法（三）分治与递归","url":"/2019/12/21/数据结构与算法（三）分治与递归/","content":"运行环境：python 3.7\n将问题分解\n函数->递归函数->分治法\n本篇介绍递归和分治\n```bash\ndef factorial(n):\n    if n == 1:\n        return 1\n    else:\n        return n*factorial(n-1)\ndef findMaximum(A,l,r):\n    m = (l+r)//2\n    if l == r-1:\n        return A[l]\n    else:\n        u = findMaximum(A,l,m)\n        v = findMaximum(A,m,r)\n        x = max(u,v)\n    return x\nif __name__ == '__main__':\n    print(factorial(4))\n    A = [1,2,4,2,3,4,6]\n    print(findMaximum(A,0,7))#l到r（不包括r）\n```\n结果如下\n![](/img/分治与递归.png)\n","tags":["数据结构与算法"]},{"title":"数据结构与算法（二）散列法","url":"/2019/12/21/数据结构与算法（二）散列法/","content":"运行环境：Dev-C++\n题目要求：\n请实现一个能执行以下命令的简单“字典”\ninsert str:向字典中添加字符串\nfind str:当前字典中包含str时输出yes，不包含str时输出no\n主要思想：将字符转变成数字，并使用散列函数H(k) = (h1(k)+i*h2(k))mod m\nh1(k)=k mod m\nh2(k)=1+ k mod (m-1)\n代码如下\n```bash\n#include<stdio.h>\n#include<string.h>\n\n#define M 1046527\n#define NIL (-1)\n#define L 14\n\nchar H[M][L];\n\nint getChar(char ch){\n\tif(ch=='A')return 1;\n\telse if(ch=='C')return 2;\n\telse if(ch=='G')return 3;\n\telse if(ch=='T')return 4;\n\telse return 0;\n} \nlong long getKey(char str[]){\n\tlong long sum=0,p=1,i;\n\tfor(i=0;i<strlen(str);i++){\n\t\tsum+=p*(getChar(str[i]));\n\t\tp*=5;\n\t}\n\treturn sum; \n}\nint h1(int key){\n\treturn key%M;\n}\nint h2(int key){\n\treturn 1+(key%(M-1));\n}\nint find(char str[]){\n\tlong long key,i,h;\n\tkey=getKey(str);\n\tfor(i=0;;i++){\n\t\th=(h1(key)+i*h2(key))%M;\n\t\tif(strcmp(H[h],str)==0)return 1;\n\t\telse if(strlen(H[h])==0)return 0;\n\t}\n\treturn 0;\n}\nint insert(char str[]){\n\tlong long key,i,h;\n\tkey = getKey(str);\n\tfor(i=0;;i++){\n\t\th=(h1(key)+i*h2(key))%M;\n\t\tif(strcmp(H[h],str)==0)return 1;\n\t\telse if(strlen(H[h])==0){\n\t\t\tstrcpy(H[h],str);\n\t\t\treturn 0;\n\t}\n\t}\n\treturn 0;\n}\nint main(){\n\tint i,n,h;\n\tchar str[L],com[9];\n\tfor(i=0;i<M;i++)H[i][0]='\\0';\n\tscanf(\"%d\",&n);\n\tfor(i=0;i<n;i++){\n\t\tscanf(\"%s %s\",com,str);\n\t\t\n\t\tif(com[0]=='i'){\n\t\t\tinsert(str);\n\t\t}else{\n\t\t\tif(find(str)){\n\t\t\t\tprintf(\"yes\\n\");\n\t\t\t}else{\n\t\t\t\tprintf(\"no\\n\");\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n```\n结果如下：\n![](/img/散列法.png)\n\n\n","tags":["数据结构与算法"]},{"title":"数据结构与算法（一）二分查找","url":"/2019/12/21/数据结构与算法（一）二分查找/","content":"运行环境：Dev-C++\n题目要求：\n有一含n个整数的数列S，含q个不相同整数的T，限制：S为升序排列\n请找出既在S又在T的整数的个数？\n代码如下\n```bash\n#include<stdio.h>\nint A[10000],n;\nbinarySearch(int key){\n\tint left=0;\n\tint right=n;\n\tint mid;\n\twhile (left<right){\t\n\t\tmid=(left+right)/2;\n\t\tif(key==A[mid])return 1;\n\t\tif(key>A[mid])left=mid+1;\n\t\telse if(key<A[mid])right=mid;\n}\n\treturn 0;\n}\nint main(){\n\tint i,q,k,sum=0;\n\tscanf(\"%d\",&n);\n\tfor(i=0;i<n;i++){\n\t\tscanf(\"%d\",&A[i]);\n\t}\n\tscanf(\"%d\",&q);\n\tfor(i=0;i<q;i++){\n\t\tscanf(\"%d\",&k);\n\t\tif(binarySearch(k))sum++;\n\t}\n\tprintf(\"%d\\n\",sum);\n\treturn 0;\n} \n```\n结果如下：\n![](/img/二分查找.png)","tags":["数据结构与算法"]}]