[{"title":"Spark操作","url":"/2019/11/30/Spark操作/","content":"欢迎来到我的博客，这篇博客将持续踩Spark实践中的各种坑。\n版本号：hbase 1.3.6\n       spark 2.4.4\n       hadoop 2.9.2\n       jdk8\n       Ubuntu 16.04.16\n## Java配置\n利用apt-get install 下载 jdk8（也可以使用官网的安装包）\n``` bash\n$ sudo apt-get install openjdk-8-jre openjdk-8-jdk\n```\n查看java 是否安装正确\n``` bash\n$ java -version\n```\n出现正确的版本号就是正确\n## hadoop伪分布配置\n主要修改core-site.xml,hdfs-site.xml两个文件\n## 安装spark\n主要修改/安装目录/spark/conf/spark-env.sh里面的设置\n## 安装sbt打包工具\nsbt version = 0.13.11\n","tags":["寒冷的一天"]}]