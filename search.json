[{"title":"post","url":"/2020/06/15/post/","content":"1、运算符~A数值类型，该如何描述？D\nA.A除以B。如果能整数除则返回商数 \nB.A和B按位取余\nC.A和B按位取与\nD.A按位取反\n2、查询语句中包含有（1-deductons[...]）这个运算，因为deductions字段是FLOAT类型的,因此数字1会提升为什么类型。C\nA.DOUBLE\nB.BIGINT\nC.FLOAT\nD.INT\n3、假设有一个表表示用户偏好，另一个表表示新闻文章，同时有一个算法会推测出用户可能会喜欢读哪些文章。这个时候就需要使用什么来生成所有用户和所有网页的对应关系的集合。B\nA.map-side JOIN\nB.笛卡尔积 JOIN\nC.RIGHT OUTER JOIN\nD.FULL OUTER JOIN\n4、哪个连接会返回左边表的记录，前提是其记录对于右边表满足ON语句中的判定条件。C\nA.笛卡尔积 JOIN\nB.RIGHT OUTER JOIN\nC.LEFT SEMI JOIN\nD.FULL OUTER JOIN\n5、Hive可以在map端执行连接过程，如果所有表中只有一个表是小表，那么可以在最大的表通过什么的时候将小表完全放到内存中。A\nA.mapper\nB.reduce\nC.select\nD.join\n6、DISTRIBUTE BY和GROUP BY在控制reducer如何接受一行行数据进行处理方面是类似的，而SORT BY则控制着什么的数据如何进行排序。A\nA.reduce内\nB.sort\nC.cluster\nD.以上都不是\n7、因为ORDER BY操作可能会导致运行时间过长，如果属性hive.mapred.mode的值是什么的话，那么Hive要求这样的语句必须加有LIMIT语句进行限制。B\nA.nonstrict\nB.strict\n8、SELECT和WHERE语句中不能引用什么表中的字段？B\nA.左边表\nB.右边表\n9、笛卡尔积是一种连接，表示左边表的行数怎么右边表的行数等于笛卡尔结果集的大小。D\nA.除以\nB.相加\nC.相减\nD.乘以\n10、左外连接通过关键字LEFT OUTER进行标识，在这种JOIN连接中，JOIN操作符左边表中符合WHERE子句的所有记录将会被返回。JOIN操作符右边表如果没有符合ON后面连接条件的记录时，那么从右边表制定选择的列的值将会是什么？C\nA.ALL\nB.NON\nC.NULL\nD.都不对\n二、判断题\n1、函数floor、round和ceil（向上取整）输入的是DOUBLE类型的值，而返回的值是BIGINT类型的，也就是将浮点型数转换成整型了。×\n2、返回值类型是DOUBLE，样式为degrees（DOUBLE d）将DOUBLE型角度值d转换成弧度值，结果是DOUBLE型的。×\n3、算数运算符接受任意的数值类型。√\n4、如果参与运算的两个数据的数据类型不同，那么两种类型中值的范围较小的那个数据类型将转换为值更大的数据类型。√\n5、用户不但可以选择则表中的列，还可以使用函数调用和算术表达式来操作列值。√\n6、对于INT类型和BIGINT类型计算，INT类型会转换提升为BIGINT类型；对于INT类型和FLOAT类型运算，INT类型将提升为FLOAT类型的。√\n7、CASE...WHEN...THEN语句和if条件语句类似，用于处理多个列的查询结果。√\n8、HAVING子句允许用户通过一个简单的语法完成原本需要通过子查询才能对FROUP BY语句产生的分组进行条件过滤的任务。√\n9、内连接中，不是只有进行连接的两个表中都存在与链接标准相匹配的数据才会被保留下来。×\n10、Hive可以在map端执行连接过程（称为map-side JOIN），这是因为Hive可以和内存中的小表进行逐一匹配，从而省略掉常规连接操作所需要的reduce过程。√[连接](https://blog.csdn.net/jinesse/article/details/80575991)\n三、解答题\n1、聚合函数是一类比较特殊的函数。其可以对多行进行一些计算，然后得到一个结果值。更确切的说，这是用户自定义聚合函数，这类函数中最有名的两个例子是哪两个？分别用于什么。\n聚合函数是一类比较特殊的函数，可以对多行进行一些计算，然后得到一个结果值，这类函数中最有名的两个例子就是count和avg，分别计算行数和平均值。[链接](https://www.jianshu.com/p/96b7b2b850bd)\n\n2、当进行算术运算时，需要注意什么问题？请详细说明。\n当进行算术运算时，用户需要注意数据溢出或数据下溢问题，Hive 遵循的是底层 Java 中数据类型的规则，因为当溢出或下溢发生时计算结果不会自动转换为更广泛的数据类型，乘法和除法最有可能会引发这个问题；[链接](https://www.cnblogs.com/jiuyi/p/4232452.html)\n\n3、与聚合函数“相反的”一类函数是什么函数？它可以做什么？\n与聚合函数“相反的”一类函数就是所谓的表生成函数，其可以将单列扩展成多列或者 多行。[链接](https://www.pianshen.com/article/1510470597/)\n\n4、SELECT语句用于什么？WHERE语句用于什么？两者结合使用又可以做什么？\n SELECT语句用于选取字段,WHERE语句用于过滤条件,两者结合使用可以查找到符合过滤条件的记录。\n\n5、GROUP BY语句通常会和聚合函数一起使用，怎么分组呢？\nGROUP BY语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个执行聚合操作。[Link](https://www.jianshu.com/p/ef4c9fb3bd5c)\n\n6、Hive可以在map端执行连接过程，Hive对于哪两个连接不支持这个优化。\nHive对于右外连接和全外连接不支持这个优化。\n\n7、UNION ALL可以将两个或多个表进行合并，每一个UNION子查询需要具有什么条件？\n只要结果集中的列数一致就可以.\n\n8、对于非常大的数据集，如何满足用户需要的是一个具有代表性的查询结果而不是全部结果？对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive可以通过对表进行抽样来满足这个需求。[link](https://blog.csdn.net/tyf2007635/article/details/98281835)\n9、如果所有表中的数据是分桶的，那么在特定的情况下对于大表同样可以使用map-side JOIN，请简单描述下应满足的条件。\n如果所有表中的数据是分桶的，那么对于大表，在特定的情况下同样可以使用这个优化，简单地说，表中的数据必须是按照ON语句中的键进行分桶的，而且其中一张表的分桶的个数必须是另一张表分桶个数的若干倍。[link](https://blog.csdn.net/xxydzyr/article/details/101012232)\n\n10、MapReduce job中传输的所有数据都是按照键值对的方式进行组织的，什么时候必须在内部使用这个功能？\nMapReduce job中传输的所有数据都是按照键值对的方式进行组织的，因此Hive在将用户的查询语句转换成MapReducejob时，其必须在内部使用这个功能。[link](https://blog.csdn.net/anzhouzan0567/article/details/101593144)\n","tags":["答案"]},{"title":"Java Stream Api","url":"/2020/03/18/Java-Stream-Api/","content":"\n不是数据结构;\n它没有内部存储，它只是用操作管道从source（数据结构、数组、generator function、IO channel）抓取数据;\n它也绝不修改自己所封装的底层数据结构的数据。例如Stream的filter操作会产生一个不包含被过滤元素的新Stream，而不是从source删除那些元素;\n所有Stream的操作必须以lambda表达式为参数;\n不支持索引访问;\n你可以请求第一个元素，但无法请求第二个，第三个，或最后一个;\n很容易生成数组或者List;\n惰性化;\n很多Stream操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始;\nIntermediate操作永远是惰性化的;\n并行能力;\n当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的;\n可以是无限的。集合有固定大小，Stream 则不必。limit(n)和findFirst()这类的short-circuiting操作可以对无限的Stream进行运算并很快完成。\n","tags":["大数据技术"]},{"title":"古代中国性格迥异的帝王","url":"/2020/03/01/古代中国性格迥异的帝王/","content":"Sima Yan (236-290), the Emperor Wu of Jin, was the founder of Jin Dynasty. It was said that he had as much as 10,000 concubines. He once issued an imperial edict to “prohibit marriage” for years and carried out large-scale beauty pageants to select women for him, which increased his harem concubines by more than 5,000 beautiful women. He had so many concubines that it was difficult for him to decide which concubine to spend the night with. So he thought of a weird way, he sat in a cart drawn by sheep and let them walk randomly in the palace, he would spent night with the lucky girl inside the room where the sheep stopped.\n\nQianlong Emperor (1711 – 1799) of Qing Dynasty is familiar to Chinese people, but he also has another status – poet. He is the poet with the most poems in the world. According to records, he composed 41863 poems in his life. While the poem collection “Quan Tang Shi” (Complete Tang Poems), the largest collection of Tang poetry, had only 48,000 from more than 2200 authors. Qianlong`s life span was 89 years which was equivalent to around 32,000 days. Removing his childhood, he had less than 30,000 days to write poetry. It means that he created more than one poem per day.\n\nZhu Youtang (1470-1505), Emperor Xiaozong of Ming Dynasty, was the only emperor who had only one wife. He only married a empress surnamed Zhang and had no concubines. They lived together like living life of ordinary people. It was not easy to do so as an emperor. It is said that he also invented the world’s first toothbrush.","tags":["外文阅读搬运"]},{"title":"Python数据分析与挖掘(一) 拉格朗日插值法","url":"/2020/01/03/Python数据分析与挖掘-一/","content":"拉格朗日插值法：根据数学知识可知，对于平面上已知的n个点，可以找到一个n-1次多项式，使此多项式曲线过n个点，语言：Python\n```bash\n#拉格朗日插值代码\nimport pandas as pd #导入数据分析库Pandas\nfrom scipy.interpolate import lagrange #导入拉格朗日插值函数\n\ninputfile = '../chapter4/demo/data/catering_sale.xls' #销量数据路径\noutputfile = '../chapter4/demo/data/sales.xls' #输出数据路径\ndata = pd.read_excel(inputfile) #读入数据\ndata[u'销量'][(data[u'销量'] < 400) | (data[u'销量'] > 5000)] = None #过滤异常值，将其变为空值\nprint(data.columns)\n#自定义列向量插值函数\n#s为列向量，n为被插值的位置，k为取前后的数据个数，默认为5\ndef ployinterp_column(s, n, k=5):\n  y = s[list(range(n-k, n)) + list(range(n+1, n+1+k))]#取数\n  y = y[y.notnull()] #剔除空值,返回一个没有空值的列向量\n  return lagrange(y.index, list(y))(n) #插值并返回插值结果\n\n#逐个元素判断是否需要插值\nfor i in data.columns:\n  for j in range(len(data)):\n    if (data[i].isnull())[j]: #如果为空即插值。\n      data[i][j] = ployinterp_column(data[i], j)\n\ndata.to_excel(outputfile) #输出结果，写入文件\n```\nlangrange(x,y)(n)这个函数表示插入缺失值所在的下标n，并用插值多项式得到近似值，详情请使用文档查看，jupyter查看方法：移动光标到相应位置shift+tab。","tags":["大数据技术"]},{"title":"Scala辅导班（二）集和映射","url":"/2020/01/02/Scala辅导班（二）集和映射/","content":"## 集和映射\n集（set）：可变集和不可变集\n映射（Map）：可变映射和不可变映射\n可变与不可变分别继承于scala.collection.mutable._和scala.collection.immutable._\n测试的完整代码如下\n```bash\nobject mapAndSet {\n  def main(args:Array[String]){\n    var jetSet = Set(\"test\",\"exam\")//不可变集\n    val jetSet2 = mutable.Set(\"tiny2\",\"nico\")\n    jetSet+=\"tiny\"\n    jetSet2+=\"negopa\"\n    println(jetSet)\n    println(jetSet2)\n    val treasureMap = mutable.Map[Int,String]()\n    treasureMap+=(1 -> \"My\")\n    treasureMap+=(2 -> \"Name\")\n    treasureMap+=(3 -> \"is\")\n    println(treasureMap(2))\n    val rumerNum = Map(1 -> \"I\",2 -> \"II\",3 -> \"III\",4 -> \"IV\")//不可变映射\n    rumerNum.foreach(s => println(s._2))\n  }\n}\n```","tags":["语言学习基础"]},{"title":"Scala辅导班(一) 使用列表","url":"/2019/12/31/Scala辅导班（一）使用列表/","content":"新年快乐，2020，向前冲！\n语言：scala 2.12\n## 数组定义\n```bash\nval numNames = Array(\"num1\",\"num2\",\"num3\")\n```\n数组定义的一般形式\n```bash\nval numNames2 = Array.apply(\"num1\",\"num2\",\"num3\")\n```\n数组定义的等价形式，使用apply方法，scala语言的本质\n## 列表定义\n```bash\nval OneTwo = List(1,2)\nval ThreeFour = List(3,4)\n```\n列表定义\n```bash\nval OneTwoThreeFour = OneTwo ::: ThreeFour\n```\n列表衔接\n```bash\nval TwoThreeFour = 2::ThreeFour\n```\n向表头添加元素，为什么是向头部添加，因为向后添加会消耗线性时间，与其这样不如向表头添加，再通过反转，就能完成同样的功能\n## 列表常用方法\n```bash\nval thrill = \"nil\"::\"sekiro\"::\"thunder\"::Nil\nprint(thrill.count(s => s.length>=4))\nprint(thrill.filter(s => s.length>=4))\nprint(thrill.forall(s => s.endsWith(\"l\")))\nthrill.foreach(s => println(s))\nprint(thrill.mkString(\",\"))//返回以\",\"分割组成的一个列表\n```\n自己动手实践，不多讲","tags":["语言学习基础"]},{"title":"Spark学习（二）概念梳理","url":"/2019/12/29/Spark学习（二）概念梳理/","content":"\n伟大领袖，天降伟人的刘老师给我们的spark概念图\n{% img /img/Spark.png 800 450 %}\n## 分区\nSpark的分区是逻辑上的分区。执行过程中有多少个Task是由RDD分区决定的。同时运行几个Task是由分配给Executor的Core的数量决定的。\n## 什么时候分区\n·分区数量从少到多·处理能力不够·数据倾斜·需要合并场景\n## cache缓存\n持久化方法，将RDD放入内存中，减少重复计算,一共有12种\n    例：\n    ```bash\n    val MEMORY_AND_DISK = new StorageLevel(true, true, false, true)\n    ```\n//第一个参数，放到磁盘\n    //第二个参数，放到内存\n    //第三个参数，磁盘中的数据，不是以java对象的方式保存\n    //第四个参数，内存中的数据，以java对象的方式保存\n## checkpoint机制\n将RDD存储在本地磁盘或者HDFS中，通过直接读取检查点目录的数据来恢复相应的RDD\n## 宽依赖窄依赖\n    宽依赖：一个父RDD和一个或多个子RDD\n    窄依赖：一个子RDD和一个或多个父RDD\n## 广播\n将数据块缓存到所有节点\n## 启动流程(9step)\n    1、跟Master建连接并申请资源，每个Executor需要 3g 内存，一共4 cores\n    2、Master进行资源调度\n    3、Master跟Worker进行rpc通信，让Worker创建Executor\n    4、Worker启动Executor\n    5、Executor跟Driver进行通信\n    6、RDD触发Action后，会根据最后这个RDD从后往前推断依赖关系，遇到shufle就切分Stage，会递归切分，递归的出口是某个RDD没有父BDD了\n    7、DAGScheduler切分完Stage后，先提交前面的Stage,执行完后在提交后面的Stage，Stage会生产Task，一个Stage 会生产很多业务逻辑相同的Task，然后将以TaskSet的形式传递给TaskScheduler\n    8、 TaskScheduler将Task序列化，根据资源情况，发送Task给Executor\n    9、Executor接收到Task后，先将Task反序列化，然后将Task用一个实现了Runnable接口的实现类包装起来，然后将该包装类丢入到线程池，然后包装类的run方法就会被执行，进而调用Task的计算逻辑\n## DStream\nDstream为每一批次的数据生成一个RDD实例，就是一个RDD序列\n## 几何平均数\n{% img /img/jihe.png 150 100 %}\n## UDF用户自定义函数\n一对一的用户定义函数，例如\n```bash\nspark.sql(\"SELECT name,age,from_unixtime(create_time,'yyyy-MM-dd HH:mm:ss') FROM t_usr\").show\n```\n实现用户自定义函数\n```bash\nspark.udf.register(\"func_name\",方法体)\n```\n多进一出UDAF（多对一）\n","tags":["大数据技术"]},{"title":"Spark学习（一）Spark集群模式讲解","url":"/2019/12/28/Spark学习（一）Spark集群模式讲解/","content":"  小坚又被Spark教训了，下面重点讲解Spark的集群\n  下面详细列举了Spark目前支持的部署模式。\n· Local模式：在本地部署单个Spark服务\n· Standalone模式：Spark自带的任务调度模式（国内常用)\n· Yarn模式：Spark使用Hadoop的YARN组件来进行\n· Mesos模式：Spark使用Mesos平台进行资源与任务的调度\n· Kubernetes模式：自Spark2.3.x版本之后才开始支持Kubernetes","tags":["大数据技术"]},{"title":"数据结构与算法（五）科赫曲线","url":"/2019/12/21/数据结构与算法（五）科赫曲线/","content":"语言：python\n递归就是常说的套娃，\n在递归函数中直接或间接调用函数，就是递归\n科赫曲线是在无限的长度中圈定有限的面积，\n实现为三步：1.找到三等分点S,T 2.做等边三角形 3.再对线段进行调用\n```bash\n#科赫曲线\nimport turtle as t\ndef koth(size,n):\n    if n==0:\n        t.fd(size)\n    else:\n        for seta in [0,60,-120,60]:\n            t.left(seta)\n            koth(size/3,n-1)\nif __name__ == '__main__':\n    koth(200,3)\n```","tags":["数据结构与算法"]},{"title":"数据结构与算法（四）穷举搜索","url":"/2019/12/21/数据结构与算法（四）穷举搜索/","content":"运行环境：python 3.7 Dev-C++\n判断是否A中的任意元素都能能够组成整数m?\npython版:\n```bash\nA = [1,5,7,10,21]\nn = len(A)\ndef solve(i,m):\n    if m==0:\n        return True\n    elif i>=n:\n        return False\n    res = solve(i+1,m) or solve(i+1,m-A[i])\n    return res\nif __name__ == '__main__':\n        if(solve(0,8)):\n            print(\"yes\")\n        else:\n            print(\"no\")\n```\nc语言版:\n```bash\n#include<stdio.h>\nint n,A[50];\nint solve(int i,int m){\n\tif (m ==0)return 1;\n\tif (i>=n)return 0;\n\tint res = solve(i+1,m)||solve(i+1,m-A[i]);\n\treturn res; \n} \nint main(){\n\tint q,M,i;\n\tscanf(\"%d\",&n);\n\tfor(i=0;i<n;i++) scanf(\"%d\",&A[i]);\n\tscanf(\"%d\",&q);\n\tfor(i=0;i<q;i++){\n\t  scanf(\"%d\",&M);\n\t  if(solve(0,M)) printf(\"yes\\n\");\n\t  else printf(\"no\\n\"); \n}\nreturn 0;\n}\n```\n","tags":["数据结构与算法"]},{"title":"数据结构与算法（三）分治与递归","url":"/2019/12/21/数据结构与算法（三）分治与递归/","content":"运行环境：python 3.7\n将问题分解\n函数->递归函数->分治法\n本篇介绍递归和分治\n```bash\ndef factorial(n):\n    if n == 1:\n        return 1\n    else:\n        return n*factorial(n-1)\ndef findMaximum(A,l,r):\n    m = (l+r)//2\n    if l == r-1:\n        return A[l]\n    else:\n        u = findMaximum(A,l,m)\n        v = findMaximum(A,m,r)\n        x = max(u,v)\n    return x\nif __name__ == '__main__':\n    print(factorial(4))\n    A = [1,2,4,2,3,4,6]\n    print(findMaximum(A,0,7))#l到r（不包括r）\n```\n结果如下\n![](/img/分治与递归.png)\n","tags":["数据结构与算法"]},{"title":"数据结构与算法（二）散列法","url":"/2019/12/21/数据结构与算法（二）散列法/","content":"运行环境：Dev-C++\n题目要求：\n请实现一个能执行以下命令的简单“字典”\ninsert str:向字典中添加字符串\nfind str:当前字典中包含str时输出yes，不包含str时输出no\n主要思想：将字符转变成数字，并使用散列函数H(k) = (h1(k)+i*h2(k))mod m\nh1(k)=k mod m\nh2(k)=1+ k mod (m-1)\n代码如下\n```bash\n#include<stdio.h>\n#include<string.h>\n\n#define M 1046527\n#define NIL (-1)\n#define L 14\n\nchar H[M][L];\n\nint getChar(char ch){\n\tif(ch=='A')return 1;\n\telse if(ch=='C')return 2;\n\telse if(ch=='G')return 3;\n\telse if(ch=='T')return 4;\n\telse return 0;\n} \nlong long getKey(char str[]){\n\tlong long sum=0,p=1,i;\n\tfor(i=0;i<strlen(str);i++){\n\t\tsum+=p*(getChar(str[i]));\n\t\tp*=5;\n\t}\n\treturn sum; \n}\nint h1(int key){\n\treturn key%M;\n}\nint h2(int key){\n\treturn 1+(key%(M-1));\n}\nint find(char str[]){\n\tlong long key,i,h;\n\tkey=getKey(str);\n\tfor(i=0;;i++){\n\t\th=(h1(key)+i*h2(key))%M;\n\t\tif(strcmp(H[h],str)==0)return 1;\n\t\telse if(strlen(H[h])==0)return 0;\n\t}\n\treturn 0;\n}\nint insert(char str[]){\n\tlong long key,i,h;\n\tkey = getKey(str);\n\tfor(i=0;;i++){\n\t\th=(h1(key)+i*h2(key))%M;\n\t\tif(strcmp(H[h],str)==0)return 1;\n\t\telse if(strlen(H[h])==0){\n\t\t\tstrcpy(H[h],str);\n\t\t\treturn 0;\n\t}\n\t}\n\treturn 0;\n}\nint main(){\n\tint i,n,h;\n\tchar str[L],com[9];\n\tfor(i=0;i<M;i++)H[i][0]='\\0';\n\tscanf(\"%d\",&n);\n\tfor(i=0;i<n;i++){\n\t\tscanf(\"%s %s\",com,str);\n\t\t\n\t\tif(com[0]=='i'){\n\t\t\tinsert(str);\n\t\t}else{\n\t\t\tif(find(str)){\n\t\t\t\tprintf(\"yes\\n\");\n\t\t\t}else{\n\t\t\t\tprintf(\"no\\n\");\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n```\n结果如下：\n![](/img/散列法.png)\n\n\n","tags":["数据结构与算法"]},{"title":"数据结构与算法（一）二分查找","url":"/2019/12/21/数据结构与算法（一）二分查找/","content":"运行环境：Dev-C++\n题目要求：\n有一含n个整数的数列S，含q个不相同整数的T，限制：S为升序排列\n请找出既在S又在T的整数的个数？\n代码如下\n```bash\n#include<stdio.h>\nint A[10000],n;\nbinarySearch(int key){\n\tint left=0;\n\tint right=n;\n\tint mid;\n\twhile (left<right){\t\n\t\tmid=(left+right)/2;\n\t\tif(key==A[mid])return 1;\n\t\tif(key>A[mid])left=mid+1;\n\t\telse if(key<A[mid])right=mid;\n}\n\treturn 0;\n}\nint main(){\n\tint i,q,k,sum=0;\n\tscanf(\"%d\",&n);\n\tfor(i=0;i<n;i++){\n\t\tscanf(\"%d\",&A[i]);\n\t}\n\tscanf(\"%d\",&q);\n\tfor(i=0;i<q;i++){\n\t\tscanf(\"%d\",&k);\n\t\tif(binarySearch(k))sum++;\n\t}\n\tprintf(\"%d\\n\",sum);\n\treturn 0;\n} \n```\n结果如下：\n![](/img/二分查找.png)","tags":["数据结构与算法"]}]